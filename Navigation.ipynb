{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Navigation\n",
    "\n",
    "---\n",
    "\n",
    "In this notebook, you will learn how to use the Unity ML-Agents environment for the first project of the [Deep Reinforcement Learning Nanodegree](https://www.udacity.com/course/deep-reinforcement-learning-nanodegree--nd893).\n",
    "\n",
    "### 1. Start the Environment\n",
    "\n",
    "We begin by importing some necessary packages.  If the code cell below returns an error, please revisit the project instructions to double-check that you have installed [Unity ML-Agents](https://github.com/Unity-Technologies/ml-agents/blob/master/docs/Installation.md) and [NumPy](http://www.numpy.org/)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unityagents import UnityEnvironment\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Next, we will start the environment!  **_Before running the code cell below_**, change the `file_name` parameter to match the location of the Unity environment that you downloaded.\n",
    "\n",
    "- **Mac**: `\"path/to/Banana.app\"`\n",
    "- **Windows** (x86): `\"path/to/Banana_Windows_x86/Banana.exe\"`\n",
    "- **Windows** (x86_64): `\"path/to/Banana_Windows_x86_64/Banana.exe\"`\n",
    "- **Linux** (x86): `\"path/to/Banana_Linux/Banana.x86\"`\n",
    "- **Linux** (x86_64): `\"path/to/Banana_Linux/Banana.x86_64\"`\n",
    "- **Linux** (x86, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86\"`\n",
    "- **Linux** (x86_64, headless): `\"path/to/Banana_Linux_NoVis/Banana.x86_64\"`\n",
    "\n",
    "For instance, if you are using a Mac, then you downloaded `Banana.app`.  If this file is in the same folder as the notebook, then the line below should appear as follows:\n",
    "```\n",
    "env = UnityEnvironment(file_name=\"Banana.app\")\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO:unityagents:\n",
      "'Academy' started successfully!\n",
      "Unity Academy name: Academy\n",
      "        Number of Brains: 1\n",
      "        Number of External Brains : 1\n",
      "        Lesson number : 0\n",
      "        Reset Parameters :\n",
      "\t\t\n",
      "Unity brain name: BananaBrain\n",
      "        Number of Visual Observations (per agent): 0\n",
      "        Vector Observation space type: continuous\n",
      "        Vector Observation space size (per agent): 37\n",
      "        Number of stacked Vector Observation: 1\n",
      "        Vector Action space type: discrete\n",
      "        Vector Action space size (per agent): 4\n",
      "        Vector Action descriptions: , , , \n"
     ]
    }
   ],
   "source": [
    "env = UnityEnvironment(file_name=\"Banana_Linux/Banana.x86_64\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Environments contain **_brains_** which are responsible for deciding the actions of their associated agents. Here we check for the first brain available, and set it as the default brain we will be controlling from Python."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the default brain\n",
    "brain_name = env.brain_names[0]\n",
    "brain = env.brains[brain_name]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Examine the State and Action Spaces\n",
    "\n",
    "The simulation contains a single agent that navigates a large environment.  At each time step, it has four actions at its disposal:\n",
    "- `0` - walk forward \n",
    "- `1` - walk backward\n",
    "- `2` - turn left\n",
    "- `3` - turn right\n",
    "\n",
    "The state space has `37` dimensions and contains the agent's velocity, along with ray-based perception of objects around agent's forward direction.  A reward of `+1` is provided for collecting a yellow banana, and a reward of `-1` is provided for collecting a blue banana. \n",
    "\n",
    "Run the code cell below to print some information about the environment."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of agents: 1\n",
      "Number of actions: 4\n",
      "States look like: [1.         0.         0.         0.         0.84408134 0.\n",
      " 0.         1.         0.         0.0748472  0.         1.\n",
      " 0.         0.         0.25755    1.         0.         0.\n",
      " 0.         0.74177343 0.         1.         0.         0.\n",
      " 0.25854847 0.         0.         1.         0.         0.09355672\n",
      " 0.         1.         0.         0.         0.31969345 0.\n",
      " 0.        ]\n",
      "States have length: 37\n"
     ]
    }
   ],
   "source": [
    "# reset the environment\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "\n",
    "# number of agents in the environment\n",
    "print('Number of agents:', len(env_info.agents))\n",
    "\n",
    "# number of actions\n",
    "action_size = brain.vector_action_space_size\n",
    "print('Number of actions:', action_size)\n",
    "\n",
    "# examine the state space \n",
    "state = env_info.vector_observations[0]\n",
    "print('States look like:', state)\n",
    "state_size = len(state)\n",
    "print('States have length:', state_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Take Random Actions in the Environment\n",
    "\n",
    "In the next code cell, you will learn how to use the Python API to control the agent and receive feedback from the environment.\n",
    "\n",
    "Once this cell is executed, you will watch the agent's performance, if it selects an action (uniformly) at random with each time step.  A window should pop up that allows you to observe the agent, as it moves through the environment.  \n",
    "\n",
    "Of course, as part of the project, you'll have to change the code so that the agent is able to use its experience to gradually choose better actions when interacting with the environment!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-28eb1cd162fd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mwhile\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrandint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction_size\u001b[0m\u001b[0;34m)\u001b[0m        \u001b[0;31m# select an action\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m     \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m# send the action to the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m     \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# get the next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m     \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                   \u001b[0;31m# get the reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             )\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "env_info = env.reset(train_mode=False)[brain_name] # reset the environment\n",
    "state = env_info.vector_observations[0]            # get the current state\n",
    "score = 0                                          # initialize the score\n",
    "while True:\n",
    "    action = np.random.randint(action_size)        # select an action\n",
    "    env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "    next_state = env_info.vector_observations[0]   # get the next state\n",
    "    reward = env_info.rewards[0]                   # get the reward\n",
    "    done = env_info.local_done[0]                  # see if episode has finished\n",
    "    score += reward                                # update the score\n",
    "    state = next_state                             # roll over the state to next time step\n",
    "    if done:                                       # exit loop if episode finished\n",
    "        break\n",
    "    \n",
    "print(\"Score: {}\".format(score))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "When finished, you can close the environment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. It's Your Turn!\n",
    "\n",
    "Now it's your turn to train your own agent to solve the environment!  When training the environment, set `train_mode=True`, so that the line for resetting the environment looks like the following:\n",
    "```python\n",
    "env_info = env.reset(train_mode=True)[brain_name]\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqn_agent import Agent\n",
    "from collections import deque\n",
    "import torch\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\r",
      "Episode 1\tAverage Score: 0.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-6-e0a6205b8d69>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# plot the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-6-e0a6205b8d69>\u001b[0m in \u001b[0;36mdqn\u001b[0;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                   \u001b[0;31m# get the reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     26\u001b[0m             \u001b[0mdone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_done\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                  \u001b[0;31m# see if episode has finished\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 27\u001b[0;31m             \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     28\u001b[0m             \u001b[0mstate\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     29\u001b[0m             \u001b[0mscore\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deep-reinforcement-learning/p1_navigation/dqn_agent.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m     46\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     47\u001b[0m         \u001b[0;31m# Save experience in replay memory\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 48\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     49\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     50\u001b[0m         \u001b[0;31m# Learn every UPDATE_EVERY time steps.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/deep-reinforcement-learning/p1_navigation/dqn_agent.py\u001b[0m in \u001b[0;36madd\u001b[0;34m(self, state, action, reward, next_state, done)\u001b[0m\n\u001b[1;32m    139\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0madd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    140\u001b[0m         \u001b[0;34m\"\"\"Add a new experience to memory.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 141\u001b[0;31m         \u001b[0me\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mexperience\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maction\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreward\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnext_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    142\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmemory\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0me\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    143\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<string>\u001b[0m in \u001b[0;36m__new__\u001b[0;34m(_cls, state, action, reward, next_state, done)\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def dqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    agent = Agent(state_size=37, action_size=4, seed=0)\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]\n",
    "\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from ddqn_agent import Agent_DDQN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 2\tAverage Score: 0.00"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-fb4ec6522e6c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     42\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 44\u001b[0;31m \u001b[0mscores\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mddqn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     45\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     46\u001b[0m \u001b[0;31m# plot the scores\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-7-fb4ec6522e6c>\u001b[0m in \u001b[0;36mddqn\u001b[0;34m(n_episodes, max_t, eps_start, eps_end, eps_decay)\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmax_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     22\u001b[0m             \u001b[0maction\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0magent\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mact\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstate\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0meps\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 23\u001b[0;31m             \u001b[0menv_info\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0maction\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mbrain_name\u001b[0m\u001b[0;34m]\u001b[0m        \u001b[0;31m# send the action to the environment\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     24\u001b[0m             \u001b[0mnext_state\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvector_observations\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m   \u001b[0;31m# get the next state\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m             \u001b[0mreward\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0menv_info\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrewards\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m                   \u001b[0;31m# get the reward\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/environment.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, vector_action, memory, text_action)\u001b[0m\n\u001b[1;32m    367\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    368\u001b[0m             outputs = self.communicator.exchange(\n\u001b[0;32m--> 369\u001b[0;31m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_generate_step_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvector_action\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmemory\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_action\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    370\u001b[0m             )\n\u001b[1;32m    371\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0moutputs\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/site-packages/unityagents/rpc_communicator.py\u001b[0m in \u001b[0;36mexchange\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     76\u001b[0m         \u001b[0mmessage\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_input\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mCopyFrom\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     77\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 78\u001b[0;31m         \u001b[0moutput\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munity_to_external\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparent_conn\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrecv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     79\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0moutput\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mheader\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstatus\u001b[0m \u001b[0;34m!=\u001b[0m \u001b[0;36m200\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36mrecv\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    248\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_closed\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    249\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_check_readable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 250\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    251\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0m_ForkingPickler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetbuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv_bytes\u001b[0;34m(self, maxsize)\u001b[0m\n\u001b[1;32m    405\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    406\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_recv_bytes\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 407\u001b[0;31m         \u001b[0mbuf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_recv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    408\u001b[0m         \u001b[0msize\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstruct\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0munpack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"!i\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbuf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgetvalue\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    409\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmaxsize\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0msize\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0mmaxsize\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/envs/drlnd/lib/python3.6/multiprocessing/connection.py\u001b[0m in \u001b[0;36m_recv\u001b[0;34m(self, size, read)\u001b[0m\n\u001b[1;32m    377\u001b[0m         \u001b[0mremaining\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    378\u001b[0m         \u001b[0;32mwhile\u001b[0m \u001b[0mremaining\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 379\u001b[0;31m             \u001b[0mchunk\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mread\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mremaining\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    380\u001b[0m             \u001b[0mn\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchunk\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    381\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mn\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;36m0\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "def ddqn(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Double Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    agent = Agent_DDQN(state_size=37, action_size=4, seed=0)\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]\n",
    "\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint_ddqn.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = ddqn()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dqnprio_agent import Agent_DQNprio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 100\tAverage Score: 0.87\n",
      "Episode 200\tAverage Score: 4.21\n",
      "Episode 300\tAverage Score: 8.56\n",
      "Episode 400\tAverage Score: 10.69\n",
      "Episode 496\tAverage Score: 13.00\n",
      "Environment solved in 396 episodes!\tAverage Score: 13.00\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "def dqn_prio(n_episodes=2000, max_t=1000, eps_start=1.0, eps_end=0.01, eps_decay=0.995):\n",
    "    \"\"\"Deep Q-Learning.\n",
    "    \n",
    "    Params\n",
    "    ======\n",
    "        n_episodes (int): maximum number of training episodes\n",
    "        max_t (int): maximum number of timesteps per episode\n",
    "        eps_start (float): starting value of epsilon, for epsilon-greedy action selection\n",
    "        eps_end (float): minimum value of epsilon\n",
    "        eps_decay (float): multiplicative factor (per episode) for decreasing epsilon\n",
    "    \"\"\"\n",
    "    agent = Agent_DQNprio(state_size=37, action_size=4, seed=0)\n",
    "    scores = []                        # list containing scores from each episode\n",
    "    scores_window = deque(maxlen=100)  # last 100 scores\n",
    "    eps = eps_start                    # initialize epsilon\n",
    "    for i_episode in range(1, n_episodes+1):\n",
    "        env_info = env.reset(train_mode=True)[brain_name] # reset the environment\n",
    "        state = env_info.vector_observations[0]\n",
    "\n",
    "        score = 0\n",
    "        for t in range(max_t):\n",
    "            action = agent.act(state, eps)\n",
    "            env_info = env.step(action)[brain_name]        # send the action to the environment\n",
    "            next_state = env_info.vector_observations[0]   # get the next state\n",
    "            reward = env_info.rewards[0]                   # get the reward\n",
    "            done = env_info.local_done[0]                  # see if episode has finished\n",
    "            agent.step(state, action, reward, next_state, done)\n",
    "            state = next_state\n",
    "            score += reward\n",
    "            if done:\n",
    "                break \n",
    "        scores_window.append(score)       # save most recent score\n",
    "        scores.append(score)              # save most recent score\n",
    "        eps = max(eps_end, eps_decay*eps) # decrease epsilon\n",
    "        print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)), end=\"\")\n",
    "        if i_episode % 100 == 0:\n",
    "            print('\\rEpisode {}\\tAverage Score: {:.2f}'.format(i_episode, np.mean(scores_window)))\n",
    "        if np.mean(scores_window)>=13.0:\n",
    "            print('\\nEnvironment solved in {:d} episodes!\\tAverage Score: {:.2f}'.format(i_episode-100, np.mean(scores_window)))\n",
    "            torch.save(agent.qnetwork_local.state_dict(), 'checkpoint_dqnprio.pth')\n",
    "            break\n",
    "    return scores\n",
    "\n",
    "scores = dqn_prio()\n",
    "\n",
    "# plot the scores\n",
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(111)\n",
    "plt.plot(np.arange(len(scores)), scores)\n",
    "plt.ylabel('Score')\n",
    "plt.xlabel('Episode #')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "drlnd",
   "language": "python",
   "name": "drlnd"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
